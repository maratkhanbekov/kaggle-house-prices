{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from scipy.special import boxcox1p, inv_boxcox1p\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from scipy.stats import skew\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxcox_transform_selective(df):\n",
    "    float_vars = df.select_dtypes('float')\n",
    "    for fv in float_vars:\n",
    "        skew_value = skew(df[fv])\n",
    "        if skew_value > 0.5:\n",
    "            sk = []\n",
    "            for lam in range(-100, 100, 1):\n",
    "                sk.append([abs(boxcox1p(df[fv], lam/1000).skew()), lam/1000])\n",
    "            lmbda = min(sk, key=lambda x: x[0])[1]\n",
    "            df[fv] = boxcox1p(df[fv], lmbda)\n",
    "    return df\n",
    "\n",
    "def dtypes_selection(df, id_col):\n",
    "    st1 = df.nunique().reset_index(name='count_unique')\n",
    "    st2 = df.describe().T.reset_index()\n",
    "    st3 = round(df.isna().sum()/df.shape[0], 2).reset_index(name='p_miss')\n",
    "    st = st1.merge(st2, on='index', how='left').merge(st3, on='index', how='left')\n",
    "    st.fillna(-1, inplace=True)\n",
    "\n",
    "    conds = [\n",
    "        st['count'] == -1,\n",
    "        st['count_unique'] == 2,\n",
    "        st['index']==id_col\n",
    "    ]\n",
    "\n",
    "    res = [\n",
    "        'object',\n",
    "        'bool',\n",
    "        'int64'\n",
    "    ]\n",
    "    st['dtype'] = np.select(conds, res, default='float64')\n",
    "    return st\n",
    "\n",
    "def fill_missing_basic(df):\n",
    "    float_vars = list(df.select_dtypes('float'))\n",
    "    object_vars = list(df.select_dtypes('object'))\n",
    "    \n",
    "    df[float_vars] = df[float_vars].fillna(0)\n",
    "    df[object_vars] = df[object_vars].fillna('none')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def outliers_replacing_basic(df):\n",
    "    float_vars = df.select_dtypes('float')\n",
    "    for fv in float_vars:\n",
    "        high_cutoff = df[fv].quantile(0.99)\n",
    "        df[fv] = np.where(df[fv]>high_cutoff, high_cutoff, df[fv])\n",
    "    return df\n",
    "\n",
    "def rmsle(y, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y, y_pred))\n",
    "\n",
    "def rmsle_cv(model, X, y, n_folds = 10):\n",
    "    kf = KFold(n_folds, shuffle=True, random_state=7).get_n_splits(X.values)\n",
    "    rmse = np.sqrt(-cross_val_score(model, X.values, y, scoring=\"neg_mean_squared_error\", cv = kf))\n",
    "    avg_score = np.mean(rmse)\n",
    "    return(avg_score)\n",
    "\n",
    "def boxcox_transform(df):\n",
    "    float_vars = df.select_dtypes('float')\n",
    "    lmbdas = []\n",
    "    for fv in float_vars:\n",
    "        sk = []\n",
    "        for lam in range(-100, 100, 1):\n",
    "            sk.append([abs(boxcox1p(df[fv], lam/1000).skew()), lam/1000])\n",
    "        \n",
    "        lmbda = min(sk, key=lambda x: x[0])[1]\n",
    "        lmbdas.append([fv, lmbda])\n",
    "        \n",
    "        df[fv] = boxcox1p(df[fv], lmbda)\n",
    "    return df, lmbdas\n",
    "\n",
    "def qqplot(X, y, model):\n",
    "    predictions = model.predict(X.values)\n",
    "    plt.scatter(y, predictions);\n",
    "    \n",
    "def transform_vars(df):\n",
    "    float_vars = list(df.select_dtypes('float'))\n",
    "    for fv in float_vars:\n",
    "        df[fv+'_sqr'] = df[fv]*df[fv]\n",
    "        df[fv+'_cube'] = df[fv]*df[fv]*df[fv]\n",
    "    return df\n",
    "\n",
    "def data_preprocessing(X_train, X_test, outliers=True, trans_vars=True, boxcox=True):\n",
    "    \n",
    "    T = pd.concat([X_train, X_test]).reset_index(drop=True)\n",
    "    \n",
    "    ### Manual I ----------------------------------\n",
    "    T['LotFrontage'] = T.groupby('Neighborhood')['LotFrontage'].transform(lambda x: x.fillna(x.median()))\n",
    "   \n",
    "    ## Missing Values ----------------------------------\n",
    "    T = fill_missing_basic(T)\n",
    "    \n",
    "    ### Manual II ----------------------------------\n",
    "    T = T.drop(['Utilities', 'Street', 'PoolQC',], axis=1)\n",
    "\n",
    "    T['YrBltAndRemod']=T['YearBuilt']+T['YearRemodAdd']\n",
    "    T['TotalSF']=T['TotalBsmtSF'] + T['1stFlrSF'] + T['2ndFlrSF']\n",
    "\n",
    "    T['Total_sqr_footage'] = (T['BsmtFinSF1'] + T['BsmtFinSF2'] +\n",
    "                                     T['1stFlrSF'] + T['2ndFlrSF'])\n",
    "\n",
    "    T['Total_Bathrooms'] = (T['FullBath'] + (0.5 * T['HalfBath']) +\n",
    "                                   T['BsmtFullBath'] + (0.5 * T['BsmtHalfBath']))\n",
    "\n",
    "    T['Total_porch_sf'] = (T['OpenPorchSF'] + T['3SsnPorch'] +\n",
    "                                  T['EnclosedPorch'] + T['ScreenPorch'] +\n",
    "                                  T['WoodDeckSF'])\n",
    "    \n",
    "    T['haspool'] = T['PoolArea'].apply(lambda x: 1 if x > 0 else 0)\n",
    "    T['has2ndFlrSF'] = T['2ndFlrSF'].apply(lambda x: 1 if x > 0 else 0)\n",
    "    T['hasgarage'] = T['GarageArea'].apply(lambda x: 1 if x > 0 else 0)\n",
    "    T['hasbsmt'] = T['TotalBsmtSF'].apply(lambda x: 1 if x > 0 else 0)\n",
    "    T['hasfireplace'] = T['Fireplaces'].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "    ### Outliers ----------------------------------\n",
    "    if outliers==True:\n",
    "        T = outliers_replacing_basic(T)\n",
    "\n",
    "    ### Square, Cube ----------------------------------\n",
    "    if trans_vars==True:\n",
    "        T = transform_vars(T)\n",
    "\n",
    "    ### BoxCox ----------------------------------\n",
    "    if boxcox==True:\n",
    "        T = boxcox_transform_selective(T)\n",
    "\n",
    "    ### Get dummies ----------------------------------\n",
    "    T = pd.get_dummies(T)\n",
    "    print(T.shape)\n",
    "\n",
    "    X_train = T.iloc[:len(X_train), :]\n",
    "    X_test = T.iloc[len(X_train):, :]\n",
    "    \n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define Types\n",
    "df_train = pd.read_csv('../input/house-prices-advanced-regression-techniques/train.csv')\n",
    "\n",
    "st = dtypes_selection(df_train, 'Id')\n",
    "dtypes = {col: dtype for col, dtype in st[['index', 'dtype']].values}\n",
    "\n",
    "### Read with dtypes\n",
    "df_train = pd.read_csv('../input/house-prices-advanced-regression-techniques/train.csv', dtype=dtypes)\n",
    "df_test = pd.read_csv('../input/house-prices-advanced-regression-techniques/test.csv', dtype=dtypes)\n",
    "\n",
    "### clean the data\n",
    "df_train = df_train[df_train.GrLivArea < 4500]\n",
    "outliers = [30, 88, 462, 631, 1322]\n",
    "df_train = df_train.drop(df_train.index[outliers])\n",
    "\n",
    "### Label X and y\n",
    "y_col = 'SalePrice'\n",
    "X_train, y_train = df_train.drop(y_col, axis=1), df_train[y_col].to_frame()\n",
    "y_train = np.log1p(y_train)\n",
    "X_test = df_test\n",
    "\n",
    "X_train, X_test = data_preprocessing(X_train, X_test)\n",
    "\n",
    "gbr = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05, max_depth=4, max_features='sqrt', min_samples_leaf=15, min_samples_split=10, loss='huber', random_state =42) \n",
    "gbr_model = gbr.fit(X_train, y_train)\n",
    "predicted_prices = gbr_model.predict(X_test)\n",
    "\n",
    "submission = pd.DataFrame({'Id': df_test.Id, 'SalePrice': predicted_prices})\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "175px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
